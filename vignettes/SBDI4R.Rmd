---
title: "Introduction to SBDI4R"
author: "Alejandro Ruete and Debora Arlt"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: TRUE
vignette: >
  %\VignetteIndexEntry{Introduction to SBDI4R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(width = 120)
```  

## Using SBDI4R

Lets assume you have already installed the package as shown in the main site \url{https://biodiversitydata-se.github.io/SBDI4R}. 

The SBDI4R package must be loaded for each new R session:

```{r}
library(SBDI4R)
```  
However, the options you stored in .Rprofile if you did it so, will load automatically with the package. Then, check that we have some additional packages that we'll use in the examples, and install them if necessary.
```{r message=FALSE}
to_install <- c("ape", "dplyr", "ggplot2", "jpeg", "maps", "mapdata",
                "maptools", "phytools", "sp", "rgeos", "tidyr", "vegan")
to_install <- to_install[!sapply(to_install, requireNamespace, quietly=TRUE)]
if(length(to_install)>0)
    install.packages(to_install, repos="http://cran.us.r-project.org")
```

#SHOULD WE BRING THE EXAMPLES FROM THE MAIN PAGE HERE?
### Example 2: Area report: what listed species exist in a given area?

Vector spatial layers (eg. Polygons) can be imported  in a number of different ways. 
Bioatlas' APIs take as search input polygons in the s.k. WKT (Well Known Text \url{https://www.geoapi.org/3.0/javadoc/org/opengis/referencing/doc-files/WKT.html}). 
So the first step is to load a vector layer and transform it into a WKT string. 
First download a .zip file with different delimitations for Sweden \url{https://www.scb.se/hitta-statistik/regional-statistik-och-kartor/regionala-indelningar/digitala-granser}
and move it somewhere you like in your computer. We recommend you move it into your 
working directory (\code{getwd()}). Extract the .zip file named KommunSweref99.zip.
<!-- We use the ALA4R's caching mechanism here, but you could equally download this file directly. -->

```{r, eval=FALSE}
# library(rgdal)
# shape <- readOGR(dsn=file.path("your/path/to/file", "Kommun_Sweref99TM_region.shp"))
```
This will only work when you set a valid filepath, and will create an object of 
class SpatialPolygon. You could instead use the data we kindly provided in this 
package \code{data("swe")} 

```{r}
shape <- swe$Municipalities
## extract just the Municipality of Örebro
shape <- shape[shape$KnNamn=="Örebro", ]
```

We could create the WKT string using the `rgeos` library:
```{r eval=FALSE}
library(rgeos)
wkt <- writeWKT(shape)
```

Unfortunately, in this instance this gives a WKT string that is too long and won't
be accepted by the web service. Also, the shapefile we just got is projected in 
the coordinate system SWEREF99 TM, and the web service only accepts coordinates in 
a geodesic coordinate system WGS84. Instead, let's construct the WKT string directly, 
which gives us a little more control over its format:
```{r}
library(sp)
shape <- spTransform(shape, CRSobj = CRS("+init=epsg:4326")) ## the magic number for WGS84
lonlat <- shape@polygons[[1]]@Polygons[[1]]@coords ## extract the polygon coordinates
## extract the convex hull of the polygon to reduce the length of the WKT string
temp <- chull(lonlat)
lonlat <- lonlat[c(temp, temp[1]), ]
## create WKT string
## first join each lon-lat coordinate pair
temp <- apply(lonlat, 1, function(z) paste(z, collapse=" "))
## now build the WKT string
wkt <- paste("POLYGON((", paste(temp, collapse=","), "))", sep="")
```

Now extract the species list in this polygon:
```{r eval=FALSE}
specieslist(wkt=wkt) %>%
    dplyr::arrange(desc(occurrenceCount)) %>%
    dplyr::select(speciesName, species, family, occurrenceCount) %>%
    head(10)
```

```{r echo=FALSE}
tryCatch({
specieslist(wkt=wkt) %>%
    dplyr::arrange(desc(occurrenceCount)) %>%
    dplyr::select(speciesName, species, family, occurrenceCount) %>%
    head(10)
}, error = function(e) { print(e$message)})
```

#FROM HERE ON NOT ADAPTED TO SBDI
### Example 4: Community composition and turnover

```{r message=FALSE}
library(vegan)
```

Define our area of interest as a transect running westwards from the Stockholm region, 
and download the occurrences of legumes (Fabaceae; a large family of flowering plants) 
in this area:
```{r eval=FALSE}
wkt <- "POLYGON((14.94 58.88, 14.94 59.69, 18.92 59.69, 18.92 58.88, 14.94 58.88))"
## define some environmental layers of interest [see sbdi_fields(fields_type = "occurrence")]
# el10011 https://spatial.bioatlas.se/ws/layers/view/more/worldclim_bio_12
# el10009 https://spatial.bioatlas.se/ws/layers/view/more/worldclim_bio_10
env_layers <- c("el10009","el10011") 
## Download the data.  We use the `occurrences()` function, adding environmental
## data via the 'extra' parameter. 
x <- occurrences(taxon="family:Fabaceae", wkt=wkt, qa="none",
                 download_reason_id="testing", extra=env_layers)
```

Convert this to a sites-by-species data.frame:
```{r eval=FALSE}
xgridded <- x$data %>%
    ## discard genus- and higher-level records
    dplyr::filter(rank %in%
                  c("species", "subspecies", "variety", "form", "cultivar")) %>%
    ## bin into 0.5-degree bins
    mutate(longitude=round(longitude*2)/2, 
           latitude=round(latitude*2)/2, 
           worldClimMeanTemperatureOfWarmestQuarter = worldClimMeanTemperatureOfWarmestQuarter /10) %>%
    ## average environmental vars within each bin
    group_by(longitude,latitude) %>%
    mutate(worldClimAnnualPrecipitation = mean(worldClimAnnualPrecipitation, na.rm=TRUE),
           worldClimMeanTemperatureOfWarmestQuarter = mean(worldClimMeanTemperatureOfWarmestQuarter, na.rm=TRUE)) %>%
    ## subset to vars of interest
    dplyr::select(longitude, latitude, species, 
                  worldClimAnnualPrecipitation,
                  worldClimMeanTemperatureOfWarmestQuarter) %>%
    ## take one row per cell per species (presence)
    distinct() %>%
    ## calculate species richness
    mutate(richness=n()) %>%
    ## convert to wide format (sites by species)
    mutate(present=1) %>%
    do(tidyr::spread(data=., key=species, value=present, fill=0)) %>%
    ungroup()
## where a species was not present, it will have NA: convert these to 0
sppcols <- setdiff(names(xgridded),
                   c("longitude", "latitude", 
                     "worldClimAnnualPrecipitation", 
                     "worldClimMeanTemperatureOfWarmestQuarter",
                     "richness"))
xgridded <- xgridded %>% mutate_at(sppcols, function(z) ifelse(is.na(z), 0, z))
```

```{r include=FALSE}
## load data from a local copy so that vignette building doesn't require downloading a big chunk of data and slow sites-by-species processing
## this file generated by running the above unevaluated code blocks, then
## saveRDS(xgridded, file="vignette_fabaceae.rds")
xgridded <- readRDS("vignette_fabaceae.rds")
sppcols <- setdiff(names(xgridded), c("longitude", "latitude", 
                                      "worldClimAnnualPrecipitation", 
                                      "worldClimMeanTemperatureOfWarmestQuarter", 
                                      "richness"))
```



The end result:
```{r}
xgridded
```

Now we can start to examine the patterns in the data. Let's plot richness as a function of longitude:
```{r warning=FALSE}
library(ggplot2)
ggplot(xgridded, aes(longitude, richness)) + 
  geom_point() + 
  theme_bw()

```
<!-- We see outliers in species richness that may be solved if names and synonyms are curated -->
<!-- as.data.frame(xgridded[xgridded$richness>200,]) -->

Species richness as a function of environment:
```{r warning=FALSE}
ggplot(xgridded, aes(worldClimMeanTemperatureOfWarmestQuarter , 
                     worldClimAnnualPrecipitation, 
                     colour=richness)) +
  scale_colour_distiller(palette="Spectral") +
  geom_point(size=8) + 
  theme_bw()
```

Higher species richness in hottest areas.

How does the community composition change along the transect? Use clustering:

```{r fig.width=6, fig.height=6}
library(vegan)
## Bray-Curtis dissimilarity
D <- vegdist(xgridded[, sppcols], "bray")
## UPGMA clustering
cl <- hclust(D, method="ave")
## plot the dendrogram
plot(cl)
## extract group labels at the 20-group level
grp <- cutree(cl, 20)
## coalesce small (outlier) groups into a single catch-all group
sing <- which(table(grp)<5)
grp[grp %in% sing] <- 21 ## put these in a new combined group
grp <- sapply(grp, function(z)which(unique(grp)==z)) ## renumber groups
xgridded$grp <- as.factor(grp)
## plot
## colours for clusters
thiscol <- c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b", "#e377c2",
             "#7f7f7f", "#bcbd22", "#17becf")
ggplot(xgridded, aes(longitude, latitude, colour=grp)) + 
  geom_point(size=5) +
  scale_colour_manual(values=thiscol) + 
  theme_bw()
## or a slightly nicer map plot
library(maps)
library(mapdata)
map("worldHires", "Sweden", 
    # xlim=c(105, 155), ylim=c(-45, -10), 
    col="gray90", fill=TRUE)
with(xgridded, points(longitude, latitude, pch=21, col=thiscol[grp], bg=thiscol[grp], cex=0.75))
```


<!-- data_resources() NOT YET IMPLEMENTED -->
<!-- ### Example 6: Retrieve assertion information for datasets -->
<!-- Compare data quality metrics for data resources -->
<!-- ```{r} -->
<!-- dr <- data_resources(druid = c('dr1411','dr90','dr361'), extra = 'assertions') -->
<!-- ``` -->

<!-- ```{r eval = FALSE} -->
<!-- # View names of all columns returned -->
<!-- names(dr) -->
<!-- ``` -->

<!-- Extract the assertion metrics from the dataset -->
<!-- ```{r warning = FALSE} -->
<!-- library(tidyr) -->
<!-- # match cols against known assertions -->
<!-- assertions <- ala_fields('assertions') -->
<!-- assert_match <- names(dr)[names(dr) %in% assertions$name] -->
<!-- dr_assert <- dr %>% select(uid, all_of(assert_match)) %>% -->
<!--   pivot_longer(-uid, names_to = "assertion", values_to = "count") %>% -->
<!--   mutate(count = as.integer(trimws(as.character(count)))) %>% -->
<!--   # build axes labels with readable assertions -->
<!--   mutate(assertion_label = tolower(gsub('([A-Z])','\n\\1',assertion))) -->
<!-- ``` -->

<!-- Plot the assertions -->
<!-- ```{r warning=FALSE} -->
<!-- library(ggplot2) -->
<!-- ggplot(dr_assert) + geom_bar(aes(x = assertion_label, y = count, -->
<!--                                  fill = uid), -->
<!--                              stat = "identity", position = "dodge", -->
<!--                              width = 2/3) + -->
<!--   theme(axis.text.x = element_text(size = 7)) +  -->
<!--   labs(x = "Assertions") -->
<!-- ``` -->

<!-- ### Example 6: Retrieve assertion information for datasets -->
<!-- Compare data quality metrics for data resources -->
<!-- ```{r} -->
<!-- dr <- data_resources(druid = c('dr1411','dr90','dr361'), extra = 'assertions') -->
<!-- ``` -->

<!-- ```{r eval = FALSE} -->
<!-- # View names of all columns returned -->
<!-- names(dr) -->
<!-- ``` -->

<!-- Extract the assertion metrics from the dataset -->
<!-- ```{r warning = FALSE} -->
<!-- library(tidyr) -->
<!-- # match cols against known assertions -->
<!-- assertions <- ala_fields('assertions') -->
<!-- assert_match <- names(dr)[names(dr) %in% assertions$name] -->
<!-- dr_assert <- dr %>% select(uid, all_of(assert_match)) %>% -->
<!--   pivot_longer(-uid, names_to = "assertion", values_to = "count") %>% -->
<!--   mutate(count = as.integer(trimws(as.character(count)))) %>% -->
<!--   # build axes labels with readable assertions -->
<!--   mutate(assertion_label = tolower(gsub('([A-Z])','\n\\1',assertion))) -->
<!-- ``` -->

<!-- Plot the assertions -->
<!-- ```{r warning=FALSE} -->
<!-- library(ggplot2) -->
<!-- ggplot(dr_assert) + geom_bar(aes(x = assertion_label, y = count, -->
<!--                                  fill = uid), -->
<!--                              stat = "identity", position = "dodge", -->
<!--                              width = 2/3) + -->
<!--   theme(axis.text.x = element_text(size = 7)) +  -->
<!--   labs(x = "Assertions") -->
<!-- ``` -->